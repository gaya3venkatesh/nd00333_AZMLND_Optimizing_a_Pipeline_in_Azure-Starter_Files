# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
This dataset contain data about a direct marketing campaign of a financial institution, based on phone calls. The aim of the campaign was to increase the number of subscribers to the bank term deposit. In this project, we seek to predict a binary variable "y" ,i.e., whether a client will subscribe to the product -marked with "yes" - or not - marked with "no".

Reference: https://archive.ics.uci.edu/ml/datasets/bank+marketing

The best performing model was a StackEnsemble Classifier generated by AutoML with the accuracy score of 0.9159332321699545. The model showed a slightly better performance as compared to that of the HytperDrive approach with the accuracy score of 0.9081436519979768.

## Scikit-learn Pipeline
The pipeline consists of data preparation, training and validation stages.

Data Preparation

A csv file containing the dataset was first converted to a TabularDataset type by using TabularDatasetFactory and then to a pandas dataframe. The data was then cleaned and prepared for the next stage of the pipeline. The output of the stage are two dataframes - the predictor variables and the target variable.

Classifier

Logistic Regression from the Scikit-Learn library was used to demonstrate the HyperDrive approach.

Training configuration using HyperDrive Package

Hyperparameters to optimise:

C - regularisation strength
max_iter - maximum number of iterations required for the classifier to converge
Reference: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regression#sklearn.linear_model.LogisticRegression

The parameter search space:

'C': 0.0001, 0.001, 0.01, 0.1, 1,10,100,1000
'max_iter': 100, 200, 300, 400, 500
Sampling method: RandomParameterSampling - random search strategy to find the values

Primary metric to optimise: Accuracy

Early termination policy: Bandit Policy

Primary metric goal: PrimaryMetricGoal.MAXIMIZE

Max total runs: 100

Training and Validation

The data was split into train (80%) and test (20%) datasets. We optimised hyperparameters by fitting multiple models with different hyperparameters on the train set and validating the models using the test set. The best run was selected and saved.


RandomParameterSampling is optimised for speed because it picks randomly hyperparameter values instead of going though every single value, i.e., it allows us to achieve an optimal primary metric for a relatively short period of time.


Bandit Policy terminates runs which fall outside of the top n% range every k interval, saving time of the experiment.

## AutoML

The model generated by AutoML was VotingEnsemble consisting of a base model - XGBoostClassifier - and a final (or meta) model - LogisticRegressionCV.

The hyperparameters generated by AutoML:
Do not know how to get the hyperparameters used by AutoML. 


## Pipeline comparison

The Hyperdrive and AutoML approaches produced quite similar accuracy scores, 0.9036418816388467 and 0.9180561271829492 respectively. A slightly greater result of the latter approach can be explained by the fact that AutoML selects estimators, performs feature engineering and chooses hyperparameters, unlike the first approach that deals with hyperparameter tuning only. In addition, the AutoML approach generated an ensemble model -- these types of models combine multiple models that, together, produce a better predictive accuracy as compared to a single model.

## Future work

We will need to tackle the issue outlined below by introducing techniques for handling imbalanced data. This will reduce the bias towards one class and, therefore, produce a more reliable model capable of recognising both classes. Alternatively, we can use a metric that is more suitable for working with imbalanced data, for example, AUC and F1 score, to get more reliable predictions. We can also use weighted score for imbalanced data.

AutoML run details:

TYPE: Class balancing detection

STATUS: ALERTED

DESCRIPTION: To decrease model bias, please cancel the current run and fix balancing problem. Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData

DETAILS: Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.

*
